x <- 16
c(x %% 7, floor(x / 7) + 1)
library("data.table")
library("infotheo")
library("tidyverse")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
f = "CS1.csv"
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq", 100)
print(object.size(data), units='Mb')
total_conditor <- function(i) {
value <- condentropy(data_disc[ , i], data_disc[ , -i])
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
}
mi_index_conditor <- function(x) {
i <- x %% length(colnames(data_disc))
j <- floor(x / length(colnames(data_disc))) + 1
print(i)
print(j)
print('-')
value <- condinformation(data_disc[, i], data_disc[, j], data_disc[, -c(i, j)])
}
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
ce_result <- unlist(lapply(1:length(colnames(data_disc)), total_conditor))
names(ce_result) <- colnames(data_disc)
ce_vec <- matrix(ce_result, nrow=length(ce_result), ncol=1)
ce_row <- matrix(ce_result, nrow=1, ncol=length(ce_result))
ce_multiplied <- ce_vec %*% ce_row
ce_multiplied <- apply(ce_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
pm_result <- mutinformation(data_disc)
pn_result <- dm_result * de_multiplied
indexer_mx <- matrix(1:(length(colnames(data_disc)) * length(colnames(data_disc))), nrow=length(colnames(data_disc)), ncol=length(colnames(data_disc)))
pm_result <- apply(indexer_mx, c(1, 2), mi_index_conditor)
library("data.table")
library("infotheo")
library("tidyverse")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
f = "CS1.csv"
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq", 100)
print(object.size(data), units='Mb')
total_conditor <- function(i) {
value <- condentropy(data_disc[ , i], data_disc[ , -i])
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
}
mi_index_conditor <- function(x) {
i <- ((x - 1) %% length(colnames(data_disc))) + 1
j <- floor(x / length(colnames(data_disc))) + 1
print(i)
print(j)
print('-')
value <- condinformation(data_disc[, i], data_disc[, j], data_disc[, -c(i, j)])
}
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
ce_result <- unlist(lapply(1:length(colnames(data_disc)), total_conditor))
names(ce_result) <- colnames(data_disc)
ce_vec <- matrix(ce_result, nrow=length(ce_result), ncol=1)
ce_row <- matrix(ce_result, nrow=1, ncol=length(ce_result))
ce_multiplied <- ce_vec %*% ce_row
ce_multiplied <- apply(ce_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
pm_result <- mutinformation(data_disc)
pn_result <- dm_result * de_multiplied
indexer_mx <- matrix(1:(length(colnames(data_disc)) * length(colnames(data_disc))), nrow=length(colnames(data_disc)), ncol=length(colnames(data_disc)))
pm_result <- apply(indexer_mx, c(1, 2), mi_index_conditor)
library("data.table")
library("infotheo")
library("tidyverse")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
f = "CS1.csv"
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq", 100)
print(object.size(data), units='Mb')
total_conditor <- function(i) {
value <- condentropy(data_disc[ , i], data_disc[ , -i])
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
}
mi_index_conditor <- function(x) {
i <- ((x - 1) %% length(colnames(data_disc))) + 1
j <- floor((x - 1) / length(colnames(data_disc))) + 1
print(i)
print(j)
print('-')
value <- condinformation(data_disc[, i], data_disc[, j], data_disc[, -c(i, j)])
}
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
ce_result <- unlist(lapply(1:length(colnames(data_disc)), total_conditor))
names(ce_result) <- colnames(data_disc)
ce_vec <- matrix(ce_result, nrow=length(ce_result), ncol=1)
ce_row <- matrix(ce_result, nrow=1, ncol=length(ce_result))
ce_multiplied <- ce_vec %*% ce_row
ce_multiplied <- apply(ce_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
pm_result <- mutinformation(data_disc)
pn_result <- dm_result * de_multiplied
indexer_mx <- matrix(1:(length(colnames(data_disc)) * length(colnames(data_disc))), nrow=length(colnames(data_disc)), ncol=length(colnames(data_disc)))
pm_result <- apply(indexer_mx, c(1, 2), mi_index_conditor)
end_time = Sys.time()
print(end_time - start_time)
library("data.table")
library("infotheo")
library("tidyverse")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
f = "CS1.csv"
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq", 100)
print(object.size(data), units='Mb')
total_conditor <- function(i) {
value <- condentropy(data_disc[ , i], data_disc[ , -i])
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
}
mi_index_conditor <- function(x) {
i <- ((x - 1) %% length(colnames(data_disc))) + 1
j <- floor((x - 1) / length(colnames(data_disc))) + 1
value <- condinformation(data_disc[, i], data_disc[, j], data_disc[, -c(i, j)])
}
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
pe_result <- unlist(lapply(1:length(colnames(data_disc)), total_conditor))
names(pe_result) <- colnames(data_disc)
pe_vec <- matrix(pe_result, nrow=length(pe_result), ncol=1)
pe_row <- matrix(pe_result, nrow=1, ncol=length(pe_result))
pe_multiplied <- pe_vec %*% pe_row
pe_multiplied <- apply(pe_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
indexer_mx <- matrix(1:(length(colnames(data_disc)) * length(colnames(data_disc))), nrow=length(colnames(data_disc)), ncol=length(colnames(data_disc)))
pm_result <- apply(indexer_mx, c(1, 2), mi_index_conditor)
pn_result <- pm_result * pe_multiplied
end_time = Sys.time()
print(end_time - start_time)
View(pm_result)
View(pn_result)
pe_result
View(dn_result)
View(pn_result)
library("data.table")
library("infotheo")
library("tidyverse")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
f = "CS2.csv"
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq", 100)
print(object.size(data), units='Mb')
total_conditor <- function(i) {
value <- condentropy(data_disc[ , i], data_disc[ , -i])
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
}
mi_index_conditor <- function(x) {
i <- ((x - 1) %% length(colnames(data_disc))) + 1
j <- floor((x - 1) / length(colnames(data_disc))) + 1
value <- condinformation(data_disc[, i], data_disc[, j], data_disc[, -c(i, j)])
}
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
pe_result <- unlist(lapply(1:length(colnames(data_disc)), total_conditor))
names(pe_result) <- colnames(data_disc)
pe_vec <- matrix(pe_result, nrow=length(pe_result), ncol=1)
pe_row <- matrix(pe_result, nrow=1, ncol=length(pe_result))
pe_multiplied <- pe_vec %*% pe_row
pe_multiplied <- apply(pe_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
indexer_mx <- matrix(1:(length(colnames(data_disc)) * length(colnames(data_disc))), nrow=length(colnames(data_disc)), ncol=length(colnames(data_disc)))
pm_result <- apply(indexer_mx, c(1, 2), mi_index_conditor)
pn_result <- pm_result * pe_multiplied
end_time = Sys.time()
print(end_time - start_time)
View(dn_result)
library("data.table")
library("ppcor")
library("tidyverse")
library("copula")
library("HiClimR")
library("infotheo")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
listed <- list.files('./pre/')
performPKe <- function(mytable) {
out <- tryCatch(
{
# Just to highlight: if you want to use more than one
# R expression in the "try" part then you'll have to
# use curly brackets.
# 'tryCatch()' will return the last evaluated expression
# in case the "try" part was completed successfully
message("This is the 'try' part")
intermediate <- pcor(mytable, method="kendall")
resulted <- intermediate$estimate
# The return value of `readLines()` is the actual value
# that will be returned in case there is no condition
# (e.g. warning or error).
# You don't need to state the return value via `return()` as code
# in the "try" part is not wrapped inside a function (unlike that
# for the condition handlers for warnings and error below)
},
error=function(cond) {
message("An error occured")
message("Here's the original error message:")
message(cond)
# Choose a return value in case of error
return(NA)
},
warning=function(cond) {
message(paste("URL caused a warning:", url))
message("Here's the original warning message:")
message(cond)
# Choose a return value in case of warning
resulted <- matrix(NA, length(colnames(mytable)), length(colnames(mytable)))
resulted = data.frame(resulted, row.names=colnames(mytable))
colnames(resulted) <- colnames(mytable)
return(resulted)
},
finally={
# NOTE:
# Here goes everything that should be executed at the end,
# regardless of success or error.
# If you want more than one expression to be executed, then you
# need to wrap them in curly brackets ({...}); otherwise you could
# just have written 'finally=<expression>'
message("Some other message at the end")
}
)
return(out)
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
return(value)
}
for (f in listed) {
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq")
print(object.size(data), units='Mb')
print('ops3')
ghoul <- corKendall(data)
write.csv(ghoul, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_kendall_direct.csv"))
ghoul <- fastCor(data)
write.csv(ghoul, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_pearson_direct.csv"))
print('ops1')
ghoul <- pcor(data, method="pearson")
dagger <- ghoul$estimate
dagger = data.frame(dagger, row.names=colnames(data))
colnames(dagger) <- colnames(data)
write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_pearson_partial.csv"))
print('ops2')
# THIS ONE IS TOO SLOW
# that would be nice if we had fast partial kendall; try to find one later
# dagger <- performPKe(data)
# write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_kendall_partial.csv"))
# entropy and conditional_entropy
# see tmp_test.R
# conditional one excluded due to 0/inf results / negative cmi
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_mututal_info_direct.csv"))
}
end_time = Sys.time()
print(end_time - start_time)
library("data.table")
library("ppcor")
library("tidyverse")
library("copula")
library("HiClimR")
library("infotheo")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
listed <- list.files('./pre/')
performPKe <- function(mytable) {
out <- tryCatch(
{
# Just to highlight: if you want to use more than one
# R expression in the "try" part then you'll have to
# use curly brackets.
# 'tryCatch()' will return the last evaluated expression
# in case the "try" part was completed successfully
message("This is the 'try' part")
intermediate <- pcor(mytable, method="kendall")
resulted <- intermediate$estimate
# The return value of `readLines()` is the actual value
# that will be returned in case there is no condition
# (e.g. warning or error).
# You don't need to state the return value via `return()` as code
# in the "try" part is not wrapped inside a function (unlike that
# for the condition handlers for warnings and error below)
},
error=function(cond) {
message("An error occured")
message("Here's the original error message:")
message(cond)
# Choose a return value in case of error
return(NA)
},
warning=function(cond) {
message(paste("URL caused a warning:", url))
message("Here's the original warning message:")
message(cond)
# Choose a return value in case of warning
resulted <- matrix(NA, length(colnames(mytable)), length(colnames(mytable)))
resulted = data.frame(resulted, row.names=colnames(mytable))
colnames(resulted) <- colnames(mytable)
return(resulted)
},
finally={
# NOTE:
# Here goes everything that should be executed at the end,
# regardless of success or error.
# If you want more than one expression to be executed, then you
# need to wrap them in curly brackets ({...}); otherwise you could
# just have written 'finally=<expression>'
message("Some other message at the end")
}
)
return(out)
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
return(value)
}
for (f in listed) {
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq")
print(object.size(data), units='Mb')
print('ops3')
ghoul <- corKendall(data)
write.csv(ghoul, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_kendall_direct.csv"))
ghoul <- fastCor(data)
write.csv(ghoul, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_pearson_direct.csv"))
print('ops1')
ghoul <- pcor(data, method="pearson")
dagger <- ghoul$estimate
dagger = data.frame(dagger, row.names=colnames(data))
colnames(dagger) <- colnames(data)
write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_pearson_partial.csv"))
print('ops2')
# THIS ONE IS TOO SLOW
# that would be nice if we had fast partial kendall; try to find one later
# dagger <- performPKe(data)
# write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_kendall_partial.csv"))
# entropy and conditional_entropy
# see tmp_test.R
# conditional one excluded due to 0/inf results / negative cmi
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_mutual_info_direct.csv"))
}
end_time = Sys.time()
print(end_time - start_time)
library("data.table")
library("ppcor")
library("tidyverse")
library("copula")
library("HiClimR")
library("infotheo")
start_time <- Sys.time()
setwd('C:/Users/Edward/Desktop/lez_crosssectional_v2/precomputed/linkage_1/')
getwd()
listed <- list.files('./pre/')
performPKe <- function(mytable) {
out <- tryCatch(
{
# Just to highlight: if you want to use more than one
# R expression in the "try" part then you'll have to
# use curly brackets.
# 'tryCatch()' will return the last evaluated expression
# in case the "try" part was completed successfully
message("This is the 'try' part")
intermediate <- pcor(mytable, method="kendall")
resulted <- intermediate$estimate
# The return value of `readLines()` is the actual value
# that will be returned in case there is no condition
# (e.g. warning or error).
# You don't need to state the return value via `return()` as code
# in the "try" part is not wrapped inside a function (unlike that
# for the condition handlers for warnings and error below)
},
error=function(cond) {
message("An error occured")
message("Here's the original error message:")
message(cond)
# Choose a return value in case of error
return(NA)
},
warning=function(cond) {
message(paste("URL caused a warning:", url))
message("Here's the original warning message:")
message(cond)
# Choose a return value in case of warning
resulted <- matrix(NA, length(colnames(mytable)), length(colnames(mytable)))
resulted = data.frame(resulted, row.names=colnames(mytable))
colnames(resulted) <- colnames(mytable)
return(resulted)
},
finally={
# NOTE:
# Here goes everything that should be executed at the end,
# regardless of success or error.
# If you want more than one expression to be executed, then you
# need to wrap them in curly brackets ({...}); otherwise you could
# just have written 'finally=<expression>'
message("Some other message at the end")
}
)
return(out)
}
fun_is <- function(x) {
value <- 1 / sqrt(x)
return(value)
}
for (f in listed) {
print(str_c("./pre/", f))
input <- { str_c("./pre/", f) }
data <- fread(input)
data_disc <- discretize(data, "equalfreq")
print(object.size(data), units='Mb')
print('ops3')
ghoul <- corKendall(data)
write.csv(ghoul, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_kendall_direct.csv"))
ghoul <- fastCor(data)
write.csv(ghoul, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_pearson_direct.csv"))
print('ops1')
ghoul <- pcor(data, method="pearson")
dagger <- ghoul$estimate
dagger = data.frame(dagger, row.names=colnames(data))
colnames(dagger) <- colnames(data)
write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_pearson_partial.csv"))
print('ops2')
# THIS ONE IS TOO SLOW
# that would be nice if we had fast partial kendall; try to find one later
# dagger <- performPKe(data)
# write.csv(dagger, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_kendall_partial.csv"))
# entropy and conditional_entropy
# see tmp_test.R
# conditional one excluded due to 0/inf results / negative cmi
de_result <- apply(data_disc, 2, entropy)
de_vec <- matrix(de_result, nrow=length(de_result), ncol=1)
de_row <- matrix(de_result, nrow=1, ncol=length(de_result))
de_multiplied <- de_vec %*% de_row
de_multiplied <- apply(de_multiplied, c(1, 2), fun_is)
dm_result <- mutinformation(data_disc)
dn_result <- dm_result * de_multiplied
write.csv(dn_result, str_c("./", substr(f, 1, nchar(f)-4), "/", "corr_mutual_info_direct.csv"))
}
end_time = Sys.time()
print(end_time - start_time)
